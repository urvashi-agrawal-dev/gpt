# Mini GPT from Scratch 🔥

A simple character-level GPT-style language model built from scratch using pure PyTorch — inspired by Andrej Karpathy’s nanoGPT.

🚀 Trained on Shakespeare text  
🧠 Built without any high-level libraries — just tensors and math  
🔁 Prototyped in Google Colab, scaled in VS Code

## Features
- Bigram token-level model
- PyTorch-based training loop
- Text generation from scratch
- Runs on CPU or GPU (CUDA optional)
- Colab + VS Code compatible

## Demo (Generated Text Example)
