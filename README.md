# Mini GPT from Scratch ğŸ”¥

A simple character-level GPT-style language model built from scratch using pure PyTorch â€” inspired by Andrej Karpathyâ€™s nanoGPT.

ğŸš€ Trained on Shakespeare text  
ğŸ§  Built without any high-level libraries â€” just tensors and math  
ğŸ” Prototyped in Google Colab, scaled in VS Code

## Features
- Bigram token-level model
- PyTorch-based training loop
- Text generation from scratch
- Runs on CPU or GPU (CUDA optional)
- Colab + VS Code compatible

## Demo (Generated Text Example)
